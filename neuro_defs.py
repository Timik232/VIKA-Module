import os
import pickle
from sentence_transformers import SentenceTransformer
from torch.utils.data import DataLoader
from vk_api.keyboard import VkKeyboard, VkKeyboardColor
from vk_api.utils import get_random_id
import vk_api
from private_api import token_api  # —Ç–æ–∫–µ–Ω –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É –≤—Å–µ—Ö, –ø–æ—ç—Ç–æ–º—É –≤—ã–Ω–µ—Å –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª.
from private_api import service_token
import nltk
import requests
import re
import random
import json
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score
from spellchecker import SpellChecker
import tokenization
from transformers import AutoModel, AutoTokenizer
from transformers import BertTokenizer, BertModel
import torch
from transformers import logging
import tensorflow as tf
from sklearn.metrics.pairwise import cosine_similarity
from transformers import DataCollatorWithPadding
import numpy as np
import evaluate
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
from transformers import pipeline
from huggingface_hub import notebook_login
from sentence_transformers import losses
from torch.utils.data import DataLoader
from sentence_transformers import InputExample
from datasets import load_dataset

# notebook_login()

logging.set_verbosity_error()

dictionary = SpellChecker(language='ru', distance=1)

vk_session = vk_api.VkApi(token=token_api)
vk = vk_session.get_api()


# –∫–ª–∞—Å—Å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ, –≤ —Ç–æ–º —á–∏—Å–ª–µ –æ —Ä–∞—Å—Å—ã–ª–∫–∞—Ö.
# –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ —ç—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –±–æ—Ç–µ, –ø–æ—ç—Ç–æ–º—É –ø—É—Å—Ç—å –±—É–¥–µ—Ç —Ç–∞–∫
class UserInfo:
    def __init__(self):
        # –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –≥—Ä—É–ø–ø—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –Ω–µ –≤–≤–æ–¥–∏—Ç—å –µ—ë –∫–∞–∂–¥—ã–π —Ä–∞–∑
        self.group = ""
        self.like = 0  # –Ω—Ä–∞–≤–∏—Ç—Å—è/–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –±–æ—Ç
        self.state = ""  # —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –µ–º—É –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å
        self.sending = []
        # —É—Å–ª–æ–≤–Ω–æ –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—ã–ª–∫–∏ –ø—Ä–∏—Å–≤–æ–∏—Ç—å False, —á—Ç–æ–±—ã –Ω–µ —Ä–∞—Å—Å—ã–ª–∞–ª, —Å–¥–µ–ª–∞–Ω–æ —Å–∫–æ—Ä–µ–µ –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞
        for i in range(11):
            self.sending.append(False)


def send_message(id, msg, stiker=None, attach=None):
    try:
        vk.messages.send(
            user_id=id,
            random_id=get_random_id(),
            message=msg,
            sticker_id=stiker,
            attachment=attach
        )
    except BaseException as ex:
        print(ex)
        return


def send_document(user_id, doc_req, message=None):
    upload = vk.VkUpload(vk_session)
    document = upload.document_message(doc_req)[0]
    print(document)
    owner_id = document['owner_id']
    doc_id = document['id']
    attachment = f'doc{owner_id}_{doc_id}'
    post = {'user_id': user_id, 'random_id': 0, "attachment": attachment}
    if message is not None:
        post['message'] = message
    try:
        vk_session.method('messages.send', post)
    except BaseException:
        send_message(id, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
        return


def send_photo(user_id, img_req, message=None):
    upload = vk_api.VkUpload(vk_session)
    photo = upload.photo_messages(img_req)[0]
    owner_id = photo['owner_id']
    photo_id = photo['id']
    attachment = f'photo{owner_id}_{photo_id}'
    post = {'user_id': user_id, 'random_id': 0, "attachment": attachment}
    if message is not None:
        post['message'] = message
    try:
        vk_session.method('messages.send', post)
    except BaseException:
        send_message(id, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É")
        return


def learn_spell(data):
    words = set()
    for name in data:
        for question in data[name]['examples']:
            question = clean_up(question)
            for word in question.split():
                words.add(word)
    dictionary.word_frequency.load_words(words)
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\dictionary.pickle', 'wb') as f:
        pickle.dump(dictionary, f)
    print("–°–ª–æ–≤–∞—Ä—å –æ–±—É—á–µ–Ω")


# def fine_tuning():
#     model_name = 'sentence-transformers/LaBSE'
#     tokenizer = AutoTokenizer.from_pretrained(model_name)
#     model = AutoModel.from_pretrained(model_name)
#
#     # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∏–∑ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞
#     vocab = tokenizer.get_vocab()
#
#     # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–ª–æ–≤–æ
#     new_word = '–≤—É—Ü'
#     vocab[new_word] = len(vocab)
#     from transformers import AutoTokenizer, AutoModel
#     import torch
#     from torch.utils.data import TensorDataset, DataLoader
#     from sentence_transformers import SentenceTransformer, InputExample
#     # –î–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö
#     sentences = ['—ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º —Å–ª–æ–≤–æ–º –≤—É—Ü', '—ç—Ç–æ –¥—Ä—É–≥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –±–µ–∑ –Ω–æ–≤—ã—Ö —Å–ª–æ–≤']
#     examples = [InputExample(texts=[s], label=0) for s in sentences]
#
#     train_data = DataLoader(TensorDataset(torch.arange(len(examples))), batch_size=2)
#     model.train()
#     for epoch in range(3):
#         for batch in train_data:
#             model.zero_grad()
#             batch = tuple(t.to('cuda') for t in batch)
#             inputs = tokenizer([examples[i].texts[0] for i in batch], padding=True, truncation=True, return_tensors='pt')
#             inputs = {k: v.to('cuda') for k, v in inputs.items()}
#             outputs = model(**inputs)[1]
#             loss = torch.mean(outputs[:, 0])
#             loss.backward()
#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

def cosine_sim(query, vectorizer):
    if os.path.isfile(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\base.pkl'):
        with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\base.pkl', "rb") as f:
            base = pickle.load(f)
            print("cosine base loaded")
    else:
        with open('jsons\\intents_dataset.json', 'r', encoding='UTF-8') as f:
            data = json.load(f)
        x = []
        y = []
        for name in data:
            for question in data[name]['examples']:
                x.append(vectorizer.encode([question]))
                y.append(name)
        base = [x,y]
        with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\base.pkl', "wb") as f:
            pickle.dump(base, f)
    elems = []
    #maximum = cosine_similarity(vectorizer.encode([query]), base[0][0])
    for i in range(1, len(base[0])):
        cos = cosine_similarity(vectorizer.encode([query]), base[0][i])
        elems.append(cos)
    # print(max(elems))
    return base[1][elems.index(max(elems))]


def transformer_classification(data):
    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

    def preprocess_function(examples):
        return tokenizer(examples["text"], truncation=True)
    imdb = {"test": [
    ],
    "train":[
    ]
    }
    accuracy = evaluate.load("accuracy")

    def compute_metrics(eval_pred):
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)
        return accuracy.compute(predictions=predictions, references=labels)

    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
    # id2label = {0: "NEGATIVE", 1: "POSITIVE"}
    # label2id = {"NEGATIVE": 0, "POSITIVE": 1}
    id2label = {}
    label2id = {}
    count = 0
    for name in data:
        for question in data[name]['examples']:
            buf = {
                "label": count,
                "text": question
                   }
            imdb["train"].append(buf)
            id2label[count] = name
            label2id[name] = count
        for phrase in data[name]['responses']:
            buf = {
                "label": count,
                "text": phrase
                   }
        count += 1

    from datasets import load_dataset

    imdb = load_dataset("imdb")
    print(imdb)
    tokenized_imdb = imdb.map(preprocess_function, batched=True)
    print(tokenized_imdb)
    #tokenized_imdb = preprocess_function(imdb)
    model = AutoModelForSequenceClassification.from_pretrained(
        "distilabert-base-uncased", num_labels=1324, id2label=id2label, label2id=label2id
    )
    # –Ω—É–∂–Ω–æ –∫–∞–∫-—Ç–æ –∑–∞–ª–æ–≥–∏–Ω–∏—Ç—å—Å—è, —Ç–æ–≥–¥–∞ –º–æ–∂–µ—Ç –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ–∫–∞ –Ω–µ—Ç
    training_args = TrainingArguments(
        output_dir="my_awesome_model",
        learning_rate=2e-5,
        per_device_train_batch_size=16,
        per_device_eval_batch_size=16,
        num_train_epochs=2,
        weight_decay=0.01,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        push_to_hub=True,
    )
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_imdb["train"],
        eval_dataset=tokenized_imdb["test"],
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
    )
    trainer.train()
    text = "–ö—É–¥–∂"
    tokenizer = AutoTokenizer.from_pretrained(trainer)
    inputs = tokenizer(text, return_tensors="pt")
    model = AutoModelForSequenceClassification.from_pretrained("stevhliu/my_awesome_model")
    with torch.no_grad():
        logits = model(**inputs).logits
    predicted_class_id = logits.argmax().item()
    print(model.config.id2label[predicted_class_id])
    classifier = pipeline("sentiment-analysis", model=trainer)
    print(classifier(text))
    # trainer.push_to_hub()
    return trainer


def fine_tuning(data, vectorizer, dictionary, model_mlp):
    train_loss = losses.MultipleNegativesRankingLoss(model=vectorizer)
    n_examples = [
    ]
    count = 0
    for name in data:
        buf = []
        for question in data[name]['examples']:
            buf.append(question)
        n_examples.append(buf)

    train_examples = []
    for i in range(len(n_examples)):
        example = n_examples[i]
        print(example)
        #print(n_examples)
        if example != "" and example != [] and len(example) >= 3:
            train_examples.append(InputExample(texts=[example[0], example[1], example[2]]))
    print(train_examples)
    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
    print(type(train_dataloader))
    vectorizer.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10)
    print(get_intent_bert("–∫—É–¥–∂", model_mlp, vectorizer, dictionary))
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\vector.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)


def make_bertnetwork():
    with open('jsons\\intents_dataset.json', 'r', encoding='UTF-8') as f:
        data = json.load(f)
    x = []
    y = []
    for name in data:
        for question in data[name]['examples']:
            x.append(clean_up(question))
            y.append(name)
        for phrase in data[name]['responses']:
            x.append(phrase)
            y.append(name)

    device = torch.device("cuda")
    vectorizer = SentenceTransformer('distiluse-base-multilingual-cased')
    vectorizer.to(device)
    x_vec = vectorizer.encode(x)
    model_mlp = MLPClassifier(hidden_layer_sizes=322, activation='relu', solver='adam', learning_rate='adaptive',
                              max_iter=1500)
    model_mlp.fit(x_vec, y)
    y_pred = model_mlp.predict(x_vec)
    print("—Ç–æ—á–Ω–æ—Å—Ç—å " + str(accuracy_score(y, y_pred)))
    print("f1 " + str(f1_score(y, y_pred, average='macro')))
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\model.pkl', 'wb') as f:
        pickle.dump(model_mlp, f)
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\vector.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)
    neuro = [model_mlp, vectorizer]
    print("–û–±—É—á–µ–Ω–æ")
    return neuro


def make_neuronetwork():
    with open('jsons\\intents_dataset.json', 'r', encoding='UTF-8') as f:
        data = json.load(f)
    x = []
    y = []
    for name in data:
        for question in data[name]['examples']:
            x.append(question)
            y.append(name)
        for phrase in data[name]['responses']:
            x.append(phrase)
            y.append(name)

    # –≤–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    vectorizer = CountVectorizer()
    X_vec = vectorizer.fit_transform(x)
    model_mlp = MLPClassifier(hidden_layer_sizes=322, activation='relu', solver='adam', learning_rate='adaptive',
                              max_iter=1500)
    model_mlp.fit(X_vec, y)
    y_pred = model_mlp.predict(X_vec)
    print("—Ç–æ—á–Ω–æ—Å—Ç—å " + str(accuracy_score(y, y_pred)))
    print("f1 " + str(f1_score(y, y_pred, average='macro')))
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\model.pkl', 'wb') as f:
        pickle.dump(model_mlp, f)
    with open(f'{os.path.dirname(os.getcwd())}\\VIKA_pickle\\vector.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)
    neuro = [model_mlp, vectorizer]
    print("–û–±—É—á–µ–Ω–æ")
    return neuro


def create_keyboard(id, text, response="start"):
    try:
        keyboard = VkKeyboard(one_time=True)
        if response == "not_that" or response == "help_me" or response == "rss" or response == "callhuman" or response == "flood":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–°—Å—ã–ª–∫–∞ –Ω–∞ –í–ö', "https://vk.com/bramind002")
        elif response == "grifon":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–°—Ç–∏–∫–µ—Ä—ã —Å –≥—Ä–∏—Ñ–æ–Ω–æ–º –≤ –¢–ì', "https://t.me/addstickers/rtumirea")
        elif response == "psychology" or response == "danger" or response == "feedback_bad" or response == "motivation" or response == "psycho" or response == "psychologist":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–ª—É–∂–±–∞',
                                         "https://student.mirea.ru/psychological_service/staff/")
        elif response == "map" or response == "location":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ù–∞–≤–∏–≥–∞—Ç–æ—Ä', "https://ischemes.ru/group/rtu-mirea/vern78")
        elif response == "rules":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–£—Å—Ç–∞–≤', "https://www.mirea.ru/upload/medialibrary/d0e/Ustav-Novyy.pdf")
            keyboard.add_openlink_button('–ü—Ä–∞–≤–∏–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ä–∞—Å–ø–æ—Ä—è–¥–∫–∞', "https://www.mirea.ru/docs/125641/")
            keyboard.add_line()
            keyboard.add_openlink_button('–≠—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–¥–µ–∫—Å',
                                         "https://student.mirea.ru/regulatory_documents/file/3f9468db49ffd14fe96c0d28d8c056bf.pdf")
        elif response == "museums":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –º—É–∑–µ—è—Ö',
                                         "https://www.mirea.ru/about/history-of-the-university/the-museum-mirea/")
        elif response == "obhodnoy":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ü—Ä–æ —Ñ–∏–∑–∫—É–ª—å—Ç—É—Ä—É', "https://student.mirea.ru/help/section/physical_education/")
        elif response == "work":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–¶–µ–Ω—Ç—Ä –∫–∞—Ä—å–µ—Ä—ã', "https://career.mirea.ru/")
        elif response == "website":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–°–∞–π—Ç –ú–ò–†–≠–ê', "https://www.mirea.ru/")
        elif response == "military" or response == "–¥–ª—è-–≤–æ–µ–Ω–∫–æ–º–∞—Ç–∞":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ü–∞–º—è—Ç–∫–∞ –≤–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω–æ–º—É', "https://student.mirea.ru/help/section/conscript/")
        elif response == "rectorate":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–†–µ–∫—Ç–æ—Ä–∞—Ç', "https://www.mirea.ru/about/administration/rektorat/")
        elif response == "library":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–°–∞–π—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏', "https://library.mirea.ru/")
        elif response == "office":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–°—Ç—É–¥–û—Ñ–∏—Å', "https://student.mirea.ru/services/")
        elif response == "scholarship":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–†–∞–∑–º–µ—Ä —Å—Ç–∏–ø–µ–Ω–¥–∏–∏',
                                         "https://student.mirea.ru/scholaship_support/scholarships/state_academic_support/")
        elif response == "social-money":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ú–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è –ø–æ–º–æ—â—å', "https://vk.com/topic-42869722_48644800")
            keyboard.add_openlink_button('–ë–ª–∞–Ω–∫–∏', "https://student.mirea.ru/statement/")
        elif response == "subsidy":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–í–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ—Ç–∞—Ü–∏—è–º', "https://vk.com/@rtuprofkom-voprosy-po-dotaciyam")
        elif response == "rzhd":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–†–ñ–î-–±–æ–Ω—É—Å', "https://vk.com/@rtuprofkom-rzhd-bonus-dlya-studentov")
        elif response == "hostel" or response == "hostel-contest":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± –æ–±—â–µ–∂–∏—Ç–∏—è—Ö', "https://student.mirea.ru/hostel/campus/")
        elif response == "vuz" or response == "vuc":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–í–£–¶', "https://vuc.mirea.ru/")
        elif response == "expedition":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–≠–∫—Å–ø–µ–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å', "https://vuc.mirea.ru/ekspeditsionnyy-korpus/")
        elif response == "diving":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–î–∞–π–≤–∏–Ω–≥ –∫–ª—É–±', "https://vuc.mirea.ru/kluby/dayving/")
        elif response == "metodichka" or response == "maps":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button('–ú–µ—Ç–æ–¥–∏—á–∫–∞ –ø–µ—Ä–≤–æ–∫—É—Ä—Å–Ω–∏–∫–∞',
                                         "https://student.mirea.ru/help/file/metod_perv_2022.pdf")
        elif response == "double-diploma":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–≤–æ–π–Ω–æ–≥–æ –¥–∏–ø–ª–æ–º–∞",
                                         "https://www.mirea.ru/international-activities/training-and-internships/")
        elif response == "car":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–æ–¥–∏—Ç–µ–ª–µ–π",
                                         "https://www.mirea.ru/about/the-structure-of-the-university/educational-scientific-structural-unit/driving-school-mstu-mirea/")
        elif response == "other-language":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–°—Å—ã–ª–∫–∞", "https://language.mirea.ru/")
        elif response == "business" or response == "softskill":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–°—Å—ã–ª–∫–∞ –Ω–∞ –≥—Ä—É–ø–ø—É", "https://vk.com/ntv.mirea")
        elif response == "–∑–∞–±—ã–ª-–≤–µ—â–∏":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ë—é—Ä–æ –Ω–∞—Ö–æ–¥–æ–∫", "https://vk.com/public79544978")
        elif response == "science":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ù–∞—É—á–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞", "https://student.mirea.ru/student_scientific_society/")
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –≤ –í–ö", "https://vk.com/mirea_smu")
        elif response == "constructor" or response == "accelerator":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ê–∫—Å–µ–ª–µ—Ä–∞—Ç–æ—Ä", "https://project.mirea.ru/")
        elif response == "uvisr":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–£–í–ò–°–†", "https://student.mirea.ru/")
        elif response == "student-union":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –≤ –í–ö", "https://vk.com/sumirea")
        elif response == "media-school":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ú–µ–¥–∏–∞—à–∫–æ–ª–∞", "https://vk.com/mediaschool_sumirea")
        elif response == "volunteer":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–í–æ–ª–æ–Ω—Ç—ë—Ä—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä", "https://vk.com/vcrtumirea")
        elif response == "atmosfera":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ê—Ç–º–æ—Å—Ñ–µ—Ä–∞", "https://vk.com/atmosfera")
        elif response == "apriori":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ê–ø—Ä–∏–æ—Ä–∏", "https://vk.com/apriori.moscow")
        elif response == "counselor":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ê—Ç–º–æ—Å—Ñ–µ—Ä–∞", "https://vk.com/atmosfera")
            keyboard.add_openlink_button("–ê–ø—Ä–∏–æ—Ä–∏", "https://vk.com/apriori.moscow")
        elif response == "rescue" or response == "rescue-contacts":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –≤ –í–ö", "https://vk.com/csovsks")
        elif response == "vector":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–í–µ–∫—Ç–æ—Ä", "https://vk.com/vector_mirea")
        elif response == "rtuitlab":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("RTUITlab", "https://vk.com/rtuitlab")
        elif response == "group-it":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–ò–¢ –≤ –í–ö", "https://vk.com/it_sumirea")
        elif response == "group-iii":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–ò–ò –≤ –í–ö", "https://vk.com/iii_sumirea")
        elif response == "group-iri":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–†–ò –≤ –í–ö", "https://vk.com/iri_sumirea")
        elif response == "group-ikb":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–ö–ë –≤ –í–ö", "https://vk.com/ikb_sumirea")
        elif response == "group-itu":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–¢–£ –≤ –í–ö", "https://vk.com/itu_sumirea")
        elif response == "group-itht":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–¢–•–¢ –≤ –í–ö", "https://vk.com/itht_sumirea")
        elif response == "group-iptip":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ò–ü–¢–ò–ü –≤ –í–ö", "https://vk.com/iptip__sumirea")
        elif response == "group-kpk":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –ö–ü–ö –≤ –í–ö", "https://vk.com/college_sumirea")
        elif response == "rating":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_button("–õ–∞–π–∫üëç", color=VkKeyboardColor.POSITIVE)
            keyboard.add_button("–î–∏–∑–ª–∞–π–∫üëé", color=VkKeyboardColor.NEGATIVE)
        elif response == "work":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–¶–µ–Ω—Ç—Ä –ö–∞—Ä—å–µ—Ä—ã", "https://vk.com/careercenterrtumirea")
        elif response == "graduate-union":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ê—Å—Å–æ—Ü–∏–∞—Ü–∏—è –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤", "https://student.mirea.ru/graduate/")
        elif response == "radio":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–†–∞–¥–∏–æ—Ä—É–±–∫–∞ –∏ –†–∞–¥–∏–æ–ª–∞–±", "https://vk.com/rtu.radio")
        elif response == "admin":
            keyboard = VkKeyboard(one_time=True)
            # keyboard.add_button("1.–í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º", color=VkKeyboardColor.PRIMARY)
            # keyboard.add_line()
            keyboard.add_button("1.–í—ã–≤–µ—Å—Ç–∏ –≤—Å–µ —Ç–µ–º—ã", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("2.–î–æ–±–∞–≤–∏—Ç—å —Ç–µ–º—É", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("3.–£–¥–∞–ª–∏—Ç—å —Ç–µ–º—É", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("4.–í—ã–≤–µ—Å—Ç–∏ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("5.–î–æ–±–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –∫ —Ç–µ–º–µ", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("6.–î–æ–±–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å –∫ —Ç–µ–º–µ", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("7.–ù–∞–π—Ç–∏ —Ç–µ–º—É –ø–æ –≤–æ–ø—Ä–æ—Å—É", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("8.–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Ä–µ–π—Ç–∏–Ω–≥", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("9.–í—ã—Ö–æ–¥", color=VkKeyboardColor.NEGATIVE)
        elif response == "statistic":
            keyboard = VkKeyboard(one_time=True)
            keyboard.add_button("1.–í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("2.–†–µ–π—Ç–∏–Ω–≥ –±–æ—Ç–∞", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("3.–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("4.–í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button("5.–í–µ—Ä–Ω—É—Ç—å—Å—è", color=VkKeyboardColor.NEGATIVE)
        elif response == "yesno":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_button("–î–∞", color=VkKeyboardColor.POSITIVE)
            keyboard.add_button("–ù–µ—Ç", color=VkKeyboardColor.NEGATIVE)
        elif response == "uch-otd" or response == "—É—á–µ–±–Ω—ã–π-–æ—Ç–¥–µ–ª-–∏—Ç":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–£—á–µ–±–Ω—ã–π –æ—Ç–¥–µ–ª",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/contacts/")
        elif response == "–ø—Ä–æ—Ñ—Å–æ—é–∑":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü—Ä–æ—Ñ—Å–æ—é–∑", "https://vk.com/rtuprofkom")
        elif response == "center_culture":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–¶–µ–Ω—Ç—Ä –∫—É–ª—å—Ç—É—Ä—ã", "https://student.mirea.ru/center_culture/creativity/")
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –≤ –í–ö –¶–ö–¢", "https://vk.com/cktmirea")
        elif response == "–≤—Ä–∏-–ª–µ—Å" or response == "—à–∫–æ–ª–∞-–ª–µ—Å–∞":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–í–†–ò –õ–µ—Å", "https://vk.com/vri_les")
        elif response == "—à–≤–∏–∑–∏—Å":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–®–í–ò–ó–ò–°", "https://vk.com/shvizis")
        elif response == "–∑–∞—è–≤–ª–µ–Ω–∏–µ-–≤-—Å—Ç—É–¥":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–í—Å—Ç—É–ø–∏—Ç—å –≤ –°—Ç—É–¥–°–æ—é–∑", "https://sumirea.ru/connect/")
        elif response == "–æ—Ç–¥–µ–ª-–ø–æ-—Ä–∞–±–æ—Ç–µ-–æ–±—â–µ–∂–∏—Ç–∏–µ":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–†–∞–±–æ—Ç–∞ —Å –æ–±—â–µ–∂–∏—Ç–∏—è–º–∏", "https://student.mirea.ru/about/section1/")
        elif response == "—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫", "https://tel.mirea.ru/")
        elif response == "–∫–∞—Ñ–µ–¥—Ä–∞-–æ–±—â–µ–π-–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institut-iskusstvennogo-intellekta/the-structure-of-the-institute/chair-of-general-informatics/")
        elif response == "–≤—Ç" or response == "–ø–ª–∞—Ç–æ–Ω–æ–≤–∞":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/kvt_mirea")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/department-of-computer-engineering/")
        elif response == "–º–æ—Å–∏—Ç" or response == "–≥–æ–ª–æ–≤–∏–Ω":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/mireamosit")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/department-of-mathematical-provision-and-standardization-of-information-technology/")
        elif response == "–∏–ø–ø–æ" or response == "–±–æ–ª–±–∞–∫–æ–≤":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/ippo_it")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/department-of-instrumental-and-applied-software/")
        elif response == "–ø–ø–∏" or response == "–ø–ø–∏-–∑–∞–≤":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/ppi_it")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/the-department-of-practical-and-applied-computer-science/")
        elif response == "–∫–∞—Ñ–µ–¥—Ä–∞-–ø–º" or response == "–¥–∑–µ—Ä–∂–∏–Ω—Å–∫–∏–π":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/kafprimat")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/the-department-of-applied-mathematics/")
        elif response == "–∫–∏—Å" or response == "–∞–¥—Ä–∏–∞–Ω–æ–≤–∞":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ì—Ä—É–ø–ø–∞ –í–ö", "https://vk.com/kis_it_mirea")
            keyboard.add_openlink_button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                                         "https://www.mirea.ru/education/the-institutes-and-faculties/institute-of-information-technology/the-structure-of-the-institute/the-department-of-corporate-information-systems/")
        elif response == "–ø—Ä–æ–≥—Ä–∞–º–º–∞-–æ–±–º–µ–Ω–∞":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–û—Ç–¥.–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞",
                                         "https://www.mirea.ru/about/the-structure-of-the-university/administrative-structural-unit/the-department-of-international-relations/the-department-of-international-cooperation/")
        elif response == "–ø–æ–ª–æ–∂–µ–Ω–∏–µ-—ç–ª–∏—Ç–Ω–æ–π" or response == "–æ—Ç—á–∏—Å–ª–µ–Ω–∏–µ-—Å-—ç–ª–∏—Ç–Ω–æ–π":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü–æ–ª–æ–∂–µ–Ω–∏–µ –≠–ª–∏—Ç–Ω–æ–π –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∏",
                                         "https://www.mirea.ru/upload/iblock/555/scb628vl1c1v3ah22653z0grta7pz3fd/pr_1179_10_09_2020_Polozhenie-po-EP.pdf")
        elif response == "—Å—Ç–∏–ø–µ–Ω–¥–∏—è-–ø–æ-–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º-–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–ü–µ—Ä–µ—á–µ–Ω—å", "https://base.garant.ru/70842752/#block_3")
        elif response == "—Å—Ç—Ä–∞–π–∫–±–æ–ª":
            keyboard = VkKeyboard(inline=True)
            keyboard.add_openlink_button("–°—Ç—Ä–∞–π–∫–±–æ–ª—å–Ω—ã–π –∫–ª—É–±", "https://vk.com/rtuairsoftvuc")
        else:
            keyboard = VkKeyboard(one_time=False)
            keyboard.add_button('–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ', color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button('–ö–∞—Ä—Ç–∞ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞', color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button('–†–∞—Å—Å—ã–ª–∫–∞', color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button('–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä–µ—Å–¥–∞—á', color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button('–ß—Ç–æ —Ç—ã —É–º–µ–µ—à—å?', color=VkKeyboardColor.PRIMARY)
            keyboard.add_line()
            keyboard.add_button('–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å', color=VkKeyboardColor.PRIMARY)
            keyboard.add_button('–û—Ü–µ–Ω–∏—Ç—å –±–æ—Ç–∞', color=VkKeyboardColor.PRIMARY)
        vk.messages.send(
            user_id=id,
            random_id=get_random_id(),
            message=text, keyboard=keyboard.get_keyboard())
    except BaseException as Exception:
        print(Exception)
        return


def tokenize(text):
    vocab_path = 'bert/vocab.txt'
    tokenizer = tokenization.FullTokenizer(vocab_file=vocab_path, do_lower_case=True)
    return tokenizer.tokenize(text)


def clean_up(text):
    text = text.lower()
    # –æ–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —à–∞–±–ª–æ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: "–≤—Å–µ, —á—Ç–æ –ù–ï —è–≤–ª—è–µ—Ç—Å—è –±—É–∫–≤–æ–π \w –∏–ª–∏ –ø—Ä–æ–±–µ–ª–æ–º \s"
    re_not_word = r'[^\w\s]'
    text = re.sub(re_not_word, '', text)
    return text


def text_match(user_text, example):
    user_text = clean_up(user_text)
    example = clean_up(example)
    if user_text.find(example) != -1:
        return True
    if example.find(user_text) != -1:
        return True
    example_len = len(example)
    difference = nltk.edit_distance(user_text, example)
    return (difference / example_len) < 0.4


users = {}


def get_intent(text, model_mlp, vectorizer, dictionary):
    corrected_text = ""
    for word in text.split():
        word = str(dictionary.correction(word))
        corrected_text += word + ' '
    # corrected_text = dictionary.correction(text)
    text_vec = vectorizer.transform([corrected_text])
    return model_mlp.predict(text_vec)[0]


def get_intent_bert(text, model_mlp, vectorizer, dictionary):
    corrected_text = ""
    for word in text.split():
        word = str(dictionary.correction(word))
        corrected_text += word + ' '
    # corrected_text = dictionary.correction(text)
    text_vec = vectorizer.encode([corrected_text])
    import pandas as pd
    proba = model_mlp.predict_proba(text_vec)[0]
    print(max(proba), corrected_text)
    # print(pd.DataFrame(columns=model_mlp.classes_, data=proba), sep="\n")
    return model_mlp.predict(text_vec)[0]


def get_response(intent, data):
    return random.choice(data[intent]['responses'])


def answering(text, model_mlp, data, vectorizer, dictionary):
    text = clean_up(text)
    if text.strip() == "" or text == " " or len(text) < 2:
        intent = "flood"
    else:
        # intent = get_intent(text, model_mlp, vectorizer, dictionary)
        intent = get_intent_bert(text, model_mlp, vectorizer, dictionary)
        # intent = cosine_sim(text, vectorizer)
    answer = get_response(intent, data)
    full_answer = [answer, intent]
    return full_answer


def add_answer(users):
    with open('jsons\\intents_dataset.json', 'r', encoding='UTF-8') as f:
        data = json.load(f)
    while True:
        print(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é:\n1.–í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º\n2.–í—ã–≤–µ—Å—Ç–∏ –≤—Å–µ —Ç–µ–º—ã\n3.–î–æ–±–∞–≤–∏—Ç—å —Ç–µ–º—É\n4.–£–¥–∞–ª–∏—Ç—å —Ç–µ–º—É\n5.–í—ã–≤–µ—Å—Ç–∏ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ\n6.–î–æ–±–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –∫ —Ç–µ–º–µ\n7.–î–æ–±–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å –∫ —Ç–µ–º–µ\n8.–í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n9.–í—ã–≤–µ—Å—Ç–∏ —Ä–µ–π—Ç–∏–Ω–≥\n10.–ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
        choice = input()
        if choice == "1":
            print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º: " + str(len(data)))
        elif choice == "2":
            for i in data:
                print(i)
        elif choice == "3":
            print("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
            intent = input()
            if intent in data:
                print("–¢–∞–∫–∞—è —Ç–µ–º–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            else:
                print("–í–≤–æ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å—ã, —á—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å, –≤–≤–µ–¥–∏—Ç–µ 0")
                flag = False
                while True:
                    question = input()
                    if question == "0":
                        break
                    if not flag:
                        data[intent] = {}
                        data[intent]['examples'] = []
                        data[intent]['responses'] = []
                        flag = True
                    data[intent]['examples'].append(question)
                print("–í–≤–æ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç—ã, —á—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å, –≤–≤–µ–¥–∏—Ç–µ 0")
                while True:
                    answer = input()
                    if answer == "0":
                        break
                    data[intent]['responses'].append(answer)
                with open('jsons\\intents_dataset.json', 'w', encoding='UTF-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                print("–û—Ç–≤–µ—Ç –±—ã–ª –∑–∞–ø–∏—Å–∞–Ω –≤ —Ñ–∞–π–ª. –í–≤–µ—Å—Ç–∏ –µ—â–µ –æ—Ç–≤–µ—Ç? (y/n)")
                end = input()
                end = end.lower()
                if end == "n" or end == "no" or end == "–Ω–µ—Ç":
                    break
                else:
                    print("–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤–≤–æ–¥–∏—Ç—å")
        elif choice == "4":
            print("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
            intent = input()
            if intent in data:
                del data[intent]
                with open('intents_dataset.json', 'w', encoding='UTF-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                print("–¢–µ–º–∞ –±—ã–ª–∞ —É–¥–∞–ª–µ–Ω–∞")
            else:
                print("–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        elif choice == "5":
            print("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
            intent = input()
            if intent in data:
                print(data[intent])
            else:
                print("–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        elif choice == "6":
            print("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
            intent = input()
            if intent in data:
                print("–í–≤–æ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç—ã, —á—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å, –≤–≤–µ–¥–∏—Ç–µ 0")
                while True:
                    answer = input()
                    if answer == "0":
                        break
                    data[intent]['responses'].append(answer)
                with open('jsons\\intents_dataset.json', 'w', encoding='UTF-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                print("–û—Ç–≤–µ—Ç –±—ã–ª –∑–∞–ø–∏—Å–∞–Ω –≤ —Ñ–∞–π–ª.")
            else:
                print("–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        elif choice == "7":
            print("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
            intent = input()
            if intent in data:
                print("–í–≤–æ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å—ã, —á—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å, –≤–≤–µ–¥–∏—Ç–µ 0")
                while True:
                    question = input()
                    if question == "0":
                        break
                    data[intent]['examples'].append(question)
                with open('jsons\\intents_dataset.json', 'w', encoding='UTF-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                print("–í–æ–ø—Ä–æ—Å—ã –±—ã–ª–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ —Ñ–∞–π–ª.")
            else:
                print("–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        elif choice == "8":
            print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–æ—Ç–∞: " + str(len(users)))
        elif choice == "9":
            rate = 0
            for i in users:
                rate += users[i].like
            print("–†–µ–π—Ç–∏–Ω–≥ –±–æ—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ –º–∏–Ω—É—Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏–∑–ª–∞–π–∫–æ–≤): " + str(rate))
        elif choice == "10":
            # make_neuronetwork()
            make_bertnetwork()
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É–Ω–∫—Ç –º–µ–Ω—é")


def parsing():
    question = []
    answer = []
    dict = {}
    offset = 0
    all_posts = []
    while offset < 1000:
        vk_page = requests.get("https://api.vk.com/method/wall.get",
                               params={
                                   'access_token': service_token,
                                   'v': 5.131,
                                   'domain': 'ask_mirea',
                                   'count': 100,
                                   'offset': offset
                               })
        # vk_page = requests.get('https://vk.com/ask_mirea')
        try:
            page = vk_page.json()['response']['items']
            all_posts.extend(page)
        except BaseException as ex:
            print(ex, vk_page)
        offset += 100
    for i in all_posts:
        try:
            msg = i['text']
            if msg.find("–í–æ–ø—Ä–æ—Å:") == -1 or msg.find('–û—Ç–≤–µ—Ç:') == -1:
                continue
            question.append(msg[msg.find("–í–æ–ø—Ä–æ—Å:"):msg.find("–û—Ç–≤–µ—Ç:"):].strip())
            answer.append(msg[msg.find("–û—Ç–≤–µ—Ç:"):].strip())
        except BaseException as ex:
            print(ex)
            print(i['text'])
    # print(question)
    # print(answer)
    for i in range(len(question)):
        # print(question[i], answer[i])
        question[i] = question[i].replace("–í–æ–ø—Ä–æ—Å:", "", 1)
        question[i] = clean_up(
            question[i].replace("–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "", 1).replace("—Å–ø–∞—Å–∏–±–æ", "").replace("\n", " ").strip())
        answer[i] = answer[i].replace("–û—Ç–≤–µ—Ç:", "", 1)
        answer[i] = answer[i].replace("–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!", "", 1).replace("–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ,", "", 1).replace("–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ.",
                                                                                                      "", 1).strip()

        tempq = [question[i]]
        tempa = [answer[i]]
        dict[f"topic{i}"] = {
            "examples": tempq,
            "responses": tempa
        }
    with open("second_dict.json", 'w', encoding='UTF-8') as f:
        json.dump(dict, f, ensure_ascii=False, indent=4)
    # print(dict)
    print("json ready")
